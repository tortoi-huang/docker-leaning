version: "3.8" 

x-datanode: &datanode_temp
  image: ${hadoop_image}
  command: ["hdfs", "datanode"]
  env_file:
    - ./config.env
  depends_on:
    namenode:
      condition: service_healthy

services:
  namenode:
    image: ${hadoop_image}
    hostname: namenode
    container_name: namenode
    command: ["hdfs", "namenode"]
    user: root
    ports:
      - 9870:9870
    env_file:
      - ./config.env
    environment:
        ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
    volumes:
      - ./data/namenode:/data/hadoop/tmp
      # - namenode_data:/data/hadoop/tmp
    healthcheck:
      test: ["CMD", "curl", "-s", "http://localhost:9870"]
      interval: 10s
      timeout: 5s
      retries: 30

  datanode1:
    << : *datanode_temp
    image: ${hadoop_image}
    hostname: datanode1
    container_name: datanode1
    user: root
    volumes:
      - ./data/datanode1:/data/hadoop/tmp
      # - ./data/datanode1_data:/data/hadoop/tmp/dfs/data
      # - datanode1_data:/data/hadoop/tmp
  datanode2:
    << : *datanode_temp
    hostname: datanode2
    container_name: datanode2
    user: root
    volumes:
      - ./data/datanode2:/data/hadoop/tmp
      # - ./data/datanode2_data:/data/hadoop/tmp/dfs/data
      # - datanode2_data:/data/hadoop/tmp
  datanode3:
    << : *datanode_temp
    hostname: datanode3
    container_name: datanode3
    user: root
    volumes:
      - ./data/datanode3:/data/hadoop/tmp
      # - ./data/datanode3_data:/data/hadoop/tmp/dfs/data
      # - datanode3_data:/data/hadoop/tmp

  resourcemanager:
    image: ${hadoop_image}
    hostname: resourcemanager
    container_name: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
      - 8088:8088
    env_file:
      - ./config.env
    volumes:
      - ./data/resourcemanager:/data/hadoop/tmp
      # - resourcemanager_data:/data/hadoop/tmp
  nodemanager:
    image: ${hadoop_image}
    hostname: nodemanager
    container_name: nodemanager
    command: ["yarn", "nodemanager"]
    env_file:
      - ./config.env
    volumes:
      - ./data/nodemanager:/data/hadoop/tmp
      # - nodemanager_data:/data/hadoop/tmp

  # hive:
  #   image: apache/hive:3.1.3
  #   depends_on:
  #     - postgres
  #   environment: 
  #     - SERVICE_NAME=hiveserver2
  #     - SERVICE_OPTS=${hive_opts}
  #     - DB_DRIVER=postgres
  #     - env IS_RESUME="true"
  #   ports:
  #     - 10000:10000
  #     - 10002:10002
  #     - 9083:9083
  #   volumes:
  #     - ./hive/hive-site.xml:/opt/hive/conf/hive-site.xml
  # postgres:
  #   # 高版本的jdbc不支持，需要替换hive上的jdbc
  #   image: bitnami/postgresql:12
  #   hostname: postgres
  #   environment: 
  #     - POSTGRESQL_USERNAME=hiveuser
  #     - POSTGRESQL_PASSWORD=hive@123
  #     - POSTGRESQL_DATABASE=metastore_db
  #   ports:
  #     - 5432

volumes:
#   kafka_0_data:
#     driver: local
#   kafka_1_data:
#     driver: local
#   kafka_2_data:
#     driver: local
  namenode_data:
    driver: local
  datanode1_data:
    driver: local
  datanode2_data:
    driver: local
  datanode3_data:
    driver: local
  resourcemanager_data:
    driver: local
  nodemanager_data:
    driver: local